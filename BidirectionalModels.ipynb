{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential \n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM,Dropout , Input , Bidirectional , concatenate, GRU,Conv1D\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "#from tensorflow.keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.optimizers import SGD, Adam\n",
    "import seaborn as sns\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import emoji\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data_to_pandas(filename = 'data/train.jsonl'):\n",
    "    X = []\n",
    "    Y = []\n",
    "    fhand = open(filename,encoding='utf8')\n",
    "    for line in fhand:\n",
    "        data = json.loads(line)\n",
    "\n",
    "        lt = data['context']\n",
    "        lt.reverse()\n",
    "        fullTweet =   data['response'] + \" \" + ''.join(lt)\n",
    "\n",
    "        X.append(fullTweet)\n",
    "        Y.append(data['label'])\n",
    " \n",
    "    \n",
    "    dfdata = pd.DataFrame({'Tweets': X,'Labels': Y}) \n",
    "\n",
    "    dfdata.to_csv(r'data/dataPandas.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data_to_pandas(filename = 'data/test.jsonl'):\n",
    "    tid = []\n",
    "    X = []\n",
    "    Y = []\n",
    "    fhand = open(filename,encoding='utf8')\n",
    "    for line in fhand:\n",
    "        data = json.loads(line)\n",
    "        tid.append(data['id'])\n",
    "        lt = data['context']\n",
    "        lt.reverse()\n",
    "        fullTweet =   data['response'] + \" \" + ''.join(lt)\n",
    "\n",
    "        X.append(fullTweet)\n",
    "        \n",
    "    \n",
    "    dftestdata = pd.DataFrame({'ID': tid,\n",
    "                   'Tweets': X})\n",
    "    \n",
    "   \n",
    "    dftestdata.to_csv(r'data/dftestdata.csv',index=False)\n",
    "\n",
    "\n",
    "    #return X_train,Y_train,X_test,Y_test,maxLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_training_data_to_pandas()\n",
    "load_test_data_to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitterdata = pd.read_csv(\"data/dataPandas.csv\")\n",
    "twitterdata.isnull().values.any()\n",
    "twitterdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCounts(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def count_regex(self, pattern, tweet):\n",
    "        return len(re.findall(pattern, tweet))\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        # fit method is used when specific operations need to be done on the train data, but not on the test data\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        count_words = X.apply(lambda x: self.count_regex(r'\\w+', x)) \n",
    "        count_mentions = X.apply(lambda x: self.count_regex(r'@\\w+', x))\n",
    "        count_hashtags = X.apply(lambda x: self.count_regex(r'#\\w+', x))\n",
    "        count_capital_words = X.apply(lambda x: self.count_regex(r'\\b[A-Z]{2,}\\b', x))\n",
    "        count_excl_quest_marks = X.apply(lambda x: self.count_regex(r'!|\\?', x))\n",
    "        count_urls = X.apply(lambda x: self.count_regex(r'http.?://[^\\s]+[\\s]?', x))\n",
    "        # We will replace the emoji symbols with a description, which makes using a regex for counting easier\n",
    "        # Moreover, it will result in having more words in the tweet\n",
    "        count_emojis = X.apply(lambda x: emoji.demojize(x)).apply(lambda x: self.count_regex(r':[a-z_&]+:', x))\n",
    "        \n",
    "        df = pd.DataFrame({'count_words': count_words\n",
    "                           , 'count_mentions': count_mentions\n",
    "                           , 'count_hashtags': count_hashtags\n",
    "                           , 'count_capital_words': count_capital_words\n",
    "                           , 'count_excl_quest_marks': count_excl_quest_marks\n",
    "                           , 'count_urls': count_urls\n",
    "                           , 'count_emojis': count_emojis\n",
    "                          })\n",
    "        \n",
    "        return df\n",
    "    \n",
    "tc = TextCounts()\n",
    "twitterdata_eda = tc.fit_transform(twitterdata.Tweets)\n",
    "#twitterdata_eda['Labels'] = twitterdata.Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitterdata_meta = twitterdata_eda.to_numpy()\n",
    "twitterdata_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanText(BaseEstimator, TransformerMixin):\n",
    "    def remove_mentions(self, input_text):\n",
    "        return re.sub(r'@\\w+', '', input_text)\n",
    "    \n",
    "    def remove_urls(self, input_text):\n",
    "        return re.sub(r'http.?://[^\\s]+[\\s]?', '', input_text)\n",
    "    \n",
    "    def emoji_oneword(self, input_text):\n",
    "        # By compressing the underscore, the emoji is kept as one word\n",
    "        return input_text.replace('_','')\n",
    "    \n",
    "    def remove_punctuation(self, input_text):\n",
    "        # Make translation table\n",
    "        punct = string.punctuation\n",
    "        trantab = str.maketrans(punct, len(punct)*' ')  # Every punctuation symbol will be replaced by a space\n",
    "        return input_text.translate(trantab)    \n",
    "   \n",
    "    def remove_digits(self, input_text):\n",
    "        return re.sub('\\d+', '', input_text)\n",
    "    \n",
    "    def to_lower(self, input_text):\n",
    "        return input_text.lower()\n",
    "    \n",
    "    def remove_stopwords(self, input_text):\n",
    "        stopwords_list = stopwords.words('english')\n",
    "        # Some words which might indicate a certain sentiment are kept via a whitelist\n",
    "        whitelist = [\"n't\", \"not\", \"no\"]\n",
    "        words = input_text.split() \n",
    "        clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
    "        return \" \".join(clean_words) \n",
    "    \n",
    "    def stemming(self, input_text):\n",
    "        porter = PorterStemmer()\n",
    "        words = input_text.split() \n",
    "        stemmed_words = [porter.stem(word) for word in words]\n",
    "        return \" \".join(stemmed_words)\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        clean_X = X.apply(self.remove_mentions).apply(self.remove_urls).apply(self.emoji_oneword).apply(self.remove_punctuation).apply(self.remove_digits).apply(self.to_lower).apply(self.remove_stopwords).apply(self.stemming)\n",
    "        return clean_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CleanText()\n",
    "twitterdata_CT = ct.fit_transform(twitterdata.Tweets)\n",
    "#twitterdata_CT.head()\n",
    "twitterdata['cTweets'] = twitterdata_CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "sentences = list(twitterdata['cTweets'])\n",
    "for sen in sentences:\n",
    "    #X.append(preprocess_text(sen))\n",
    "    X.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = twitterdata['Labels']\n",
    "\n",
    "y = np.array(list(map(lambda x: 1 if x==\"SARCASM\" else 0, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_train_meta, X_test_meta, y_train_meta, y_test_meta = train_test_split(twitterdata_eda, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 160\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dictionary = dict()\n",
    "#glove_file = open('./Data/glove.twitter.27B.100d.txt', encoding=\"utf8\")\n",
    "glove_file = open('./Data/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 160)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 160, 100)     1968800     input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 7)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 128)          63744       embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 8)            64          input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 136)          0           bidirectional_9[0][0]            \n",
      "                                                                 dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 136)          0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1)            137         dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,032,745\n",
      "Trainable params: 2,032,745\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nlp_input1 = Input(shape=(maxlen,)) \n",
    "meta_input1 = Input(shape=(7,))\n",
    "emb1 = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=True)(nlp_input1) \n",
    "x = Dense(8, activation=\"relu\")(meta_input1)\n",
    "nlp_out1 = Bidirectional(GRU(64))(emb1) \n",
    "concat1 = concatenate([nlp_out1, x]) \n",
    "drop1 = Dropout(0.5)(concat1)\n",
    "output1 = Dense(1, activation='sigmoid')(drop1) \n",
    "model_bgru = Model(inputs=[nlp_input1 , meta_input1], outputs=[output1])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience =1)\n",
    "rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "model_bgru.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model_bgru.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.4358 - acc: 0.5232\n",
      "Epoch 00001: val_acc improved from -inf to 0.57300, saving model to best_model.h5\n",
      "63/63 [==============================] - 8s 131ms/step - loss: 1.4358 - acc: 0.5232 - val_loss: 0.6808 - val_acc: 0.5730\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7299 - acc: 0.6370\n",
      "Epoch 00002: val_acc improved from 0.57300 to 0.68200, saving model to best_model.h5\n",
      "63/63 [==============================] - 8s 123ms/step - loss: 0.7299 - acc: 0.6370 - val_loss: 0.5841 - val_acc: 0.6820\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5054 - acc: 0.7538\n",
      "Epoch 00003: val_acc improved from 0.68200 to 0.71600, saving model to best_model.h5\n",
      "63/63 [==============================] - 8s 132ms/step - loss: 0.5054 - acc: 0.7538 - val_loss: 0.5508 - val_acc: 0.7160\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4242 - acc: 0.8145\n",
      "Epoch 00004: val_acc improved from 0.71600 to 0.72600, saving model to best_model.h5\n",
      "63/63 [==============================] - 8s 134ms/step - loss: 0.4242 - acc: 0.8145 - val_loss: 0.5463 - val_acc: 0.7260\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3478 - acc: 0.8545\n",
      "Epoch 00005: val_acc improved from 0.72600 to 0.73800, saving model to best_model.h5\n",
      "63/63 [==============================] - 8s 134ms/step - loss: 0.3478 - acc: 0.8545 - val_loss: 0.5653 - val_acc: 0.7380\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model_bgru.fit([X_train,X_train_meta ], y_train, batch_size=64, epochs=15, verbose=1, validation_data = ([X_test,X_test_meta], y_test), callbacks=[es, mc,rlrp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 32ms/step - loss: 0.5653 - acc: 0.7380\n"
     ]
    }
   ],
   "source": [
    "\n",
    "saved_model = load_model('best_model.h5')\n",
    "score,accuracy = saved_model.evaluate([X_test,X_test_meta], y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.5652762651443481\n",
      "Test Accuracy: 0.7379999756813049\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Score:\", score)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.5652762651443481\n",
      "Test Accuracy: 0.7379999756813049\n",
      "1000\n",
      "[[340 160]\n",
      " [102 398]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Test Score:\", score)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "y_pred = saved_model.predict([X_test,X_test_meta])\n",
    "y_pred =(y_pred>0.5)\n",
    "print(len(y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.68, 0.7692307692307693, 0.721868365180467)\n"
     ]
    }
   ],
   "source": [
    "def myscores(smat): \n",
    "    tp = smat[0][0] \n",
    "    fp = smat[0][1] \n",
    "    fn = smat[1][0] \n",
    "    tn = smat[1][1] \n",
    "    p = tp/(tp+fp)\n",
    "    r = tp/(tp+fn)\n",
    "    f1 = (2*p*r)/(p+r)\n",
    "    return p,r,f1\n",
    "\n",
    "print(myscores(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "twittertestdata = pd.read_csv(\"data/dftestdata.csv\")\n",
    "print(twittertestdata.isnull().values.any())\n",
    "twittertestdata_CT = ct.fit_transform(twittertestdata.Tweets)\n",
    "twittertestdata_eda = tc.fit_transform(twittertestdata.Tweets)\n",
    "twittertestdata_meta = twittertestdata_eda.to_numpy()\n",
    "\n",
    "\n",
    "twittertestdata['cTweets'] = twittertestdata_CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = []\n",
    "sentences = list(twittertestdata['cTweets'])\n",
    "for sen in sentences:\n",
    "    X_val.append(sen)\n",
    "    \n",
    "X_validate = tokenizer.texts_to_sequences(X_val)\n",
    "#X_valTokens = tokenizer.texts_to_sequences(X_validate)\n",
    "X_valTokens = pad_sequences(X_validate, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = saved_model.predict([X_valTokens,twittertestdata_meta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "twittertestdata['Predict'] = validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "twittertestdata['PLabel'] = np.where(twittertestdata['Predict'] > 0.5, \"SARCASM\", \"NOT_SARCASM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>cTweets</th>\n",
       "      <th>Predict</th>\n",
       "      <th>PLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter_1</td>\n",
       "      <td>@USER @USER @USER My 3 year old , that just fi...</td>\n",
       "      <td>year old finish read nietzsch ask ayo papa peo...</td>\n",
       "      <td>0.185304</td>\n",
       "      <td>NOT_SARCASM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twitter_2</td>\n",
       "      <td>@USER @USER How many verifiable lies has he to...</td>\n",
       "      <td>mani verifi lie told document truth teller sur...</td>\n",
       "      <td>0.835063</td>\n",
       "      <td>SARCASM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twitter_3</td>\n",
       "      <td>@USER @USER @USER Maybe Docs just a scrub of a...</td>\n",
       "      <td>mayb doc scrub coach mean get hammer gold stan...</td>\n",
       "      <td>0.829247</td>\n",
       "      <td>SARCASM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twitter_4</td>\n",
       "      <td>@USER @USER is just a cover up for the real ha...</td>\n",
       "      <td>cover real hate insid left nutshel url hate pl...</td>\n",
       "      <td>0.119860</td>\n",
       "      <td>NOT_SARCASM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twitter_5</td>\n",
       "      <td>@USER @USER @USER The irony being that he even...</td>\n",
       "      <td>ironi even ask quit articul consid comment fin...</td>\n",
       "      <td>0.965434</td>\n",
       "      <td>SARCASM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                             Tweets  \\\n",
       "0  twitter_1  @USER @USER @USER My 3 year old , that just fi...   \n",
       "1  twitter_2  @USER @USER How many verifiable lies has he to...   \n",
       "2  twitter_3  @USER @USER @USER Maybe Docs just a scrub of a...   \n",
       "3  twitter_4  @USER @USER is just a cover up for the real ha...   \n",
       "4  twitter_5  @USER @USER @USER The irony being that he even...   \n",
       "\n",
       "                                             cTweets   Predict       PLabel  \n",
       "0  year old finish read nietzsch ask ayo papa peo...  0.185304  NOT_SARCASM  \n",
       "1  mani verifi lie told document truth teller sur...  0.835063      SARCASM  \n",
       "2  mayb doc scrub coach mean get hammer gold stan...  0.829247      SARCASM  \n",
       "3  cover real hate insid left nutshel url hate pl...  0.119860  NOT_SARCASM  \n",
       "4  ironi even ask quit articul consid comment fin...  0.965434      SARCASM  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twittertestdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "twittertestdata.to_csv('answer_bgru.txt', columns = [\"ID\" , \"PLabel\"] , header = False , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 160)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 160, 100)     1968800     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 7)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 256)          234496      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 8)            64          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 264)          0           bidirectional_1[0][0]            \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 264)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            265         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,203,625\n",
      "Trainable params: 2,203,625\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nlp_input1 = Input(shape=(maxlen,)) \n",
    "meta_input1 = Input(shape=(7,))\n",
    "#emb = Embedding(output_dim=embedding_size, input_dim=100, input_length=seq_length)\n",
    "emb1 = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=True)(nlp_input1) \n",
    "#lstm = LSTM(300, dropout=0.3, recurrent_dropout=0.3)(embed)\n",
    "#nlp_out2 = Bidirectional(LSTM(128))(meta_input1) \n",
    "x = Dense(8, activation=\"relu\")(meta_input1)\n",
    "\n",
    "\n",
    "nlp_out1 = Bidirectional(LSTM(128))(emb1) \n",
    "concat1 = concatenate([nlp_out1, x]) \n",
    "drop1 = Dropout(0.6)(concat1)\n",
    "#dens = Dense(1)(drop)\n",
    "\n",
    "#classifier = Dense(32, activation='relu')(drop) \n",
    "output1 = Dense(1, activation='sigmoid')(drop1) \n",
    "model_blstm = Model(inputs=[nlp_input1 , meta_input1], outputs=[output1])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience =2)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "model_blstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model_blstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.3905 - acc: 0.5343\n",
      "Epoch 00001: val_acc improved from -inf to 0.59500, saving model to best_model.h5\n",
      "63/63 [==============================] - 20s 321ms/step - loss: 2.3905 - acc: 0.5343 - val_loss: 0.6556 - val_acc: 0.5950\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8089 - acc: 0.6453\n",
      "Epoch 00002: val_acc improved from 0.59500 to 0.69500, saving model to best_model.h5\n",
      "63/63 [==============================] - 18s 280ms/step - loss: 0.8089 - acc: 0.6453 - val_loss: 0.6507 - val_acc: 0.6950\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5401 - acc: 0.7312\n",
      "Epoch 00003: val_acc did not improve from 0.69500\n",
      "63/63 [==============================] - 18s 282ms/step - loss: 0.5401 - acc: 0.7312 - val_loss: 0.5945 - val_acc: 0.6810\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4866 - acc: 0.7697\n",
      "Epoch 00004: val_acc improved from 0.69500 to 0.70200, saving model to best_model.h5\n",
      "63/63 [==============================] - 18s 286ms/step - loss: 0.4866 - acc: 0.7697 - val_loss: 0.5535 - val_acc: 0.7020\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4388 - acc: 0.7935\n",
      "Epoch 00005: val_acc improved from 0.70200 to 0.71100, saving model to best_model.h5\n",
      "63/63 [==============================] - 18s 291ms/step - loss: 0.4388 - acc: 0.7935 - val_loss: 0.5500 - val_acc: 0.7110\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3930 - acc: 0.8322\n",
      "Epoch 00006: val_acc did not improve from 0.71100\n",
      "63/63 [==============================] - 18s 293ms/step - loss: 0.3930 - acc: 0.8322 - val_loss: 0.6024 - val_acc: 0.6920\n",
      "Epoch 7/15\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3438 - acc: 0.8597\n",
      "Epoch 00007: val_acc improved from 0.71100 to 0.71700, saving model to best_model.h5\n",
      "63/63 [==============================] - 18s 290ms/step - loss: 0.3438 - acc: 0.8597 - val_loss: 0.5864 - val_acc: 0.7170\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model_blstm.fit([X_train,X_train_meta ], y_train, batch_size=64, epochs=15, verbose=1, validation_data = ([X_test,X_test_meta], y_test), callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 39ms/step - loss: 0.5864 - acc: 0.7170\n"
     ]
    }
   ],
   "source": [
    "saved_model = load_model('best_model.h5')\n",
    "score,accuracy = saved_model.evaluate([X_test,X_test_meta], y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.586414635181427\n",
      "Test Accuracy: 0.7170000076293945\n",
      "[[334 166]\n",
      " [110 390]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Score:\", score)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "y_pred = saved_model.predict([X_test,X_test_meta])\n",
    "y_pred =(y_pred>0.6)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.668, 0.7522522522522522, 0.7076271186440679)\n"
     ]
    }
   ],
   "source": [
    "def myscores(smat): \n",
    "    tp = smat[0][0] \n",
    "    fp = smat[0][1] \n",
    "    fn = smat[1][0] \n",
    "    tn = smat[1][1] \n",
    "    p = tp/(tp+fp)\n",
    "    r = tp/(tp+fn)\n",
    "    f1 = (2*p*r)/(p+r)\n",
    "    return p,r,f1\n",
    "\n",
    "print(myscores(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = saved_model.predict([X_valTokens,twittertestdata_meta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "twittertestdata['Predict'] = validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "twittertestdata['PLabel'] = np.where(twittertestdata['Predict'] > 0.5, \"SARCASM\", \"NOT_SARCASM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>cTweets</th>\n",
       "      <th>Predict</th>\n",
       "      <th>PLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter_1</td>\n",
       "      <td>@USER @USER @USER My 3 year old , that just fi...</td>\n",
       "      <td>year old finish read nietzsch ask ayo papa peo...</td>\n",
       "      <td>0.542652</td>\n",
       "      <td>SARCASM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twitter_2</td>\n",
       "      <td>@USER @USER How many verifiable lies has he to...</td>\n",
       "      <td>mani verifi lie told document truth teller sur...</td>\n",
       "      <td>0.936665</td>\n",
       "      <td>SARCASM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twitter_3</td>\n",
       "      <td>@USER @USER @USER Maybe Docs just a scrub of a...</td>\n",
       "      <td>mayb doc scrub coach mean get hammer gold stan...</td>\n",
       "      <td>0.776727</td>\n",
       "      <td>SARCASM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twitter_4</td>\n",
       "      <td>@USER @USER is just a cover up for the real ha...</td>\n",
       "      <td>cover real hate insid left nutshel url hate pl...</td>\n",
       "      <td>0.297881</td>\n",
       "      <td>NOT_SARCASM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twitter_5</td>\n",
       "      <td>@USER @USER @USER The irony being that he even...</td>\n",
       "      <td>ironi even ask quit articul consid comment fin...</td>\n",
       "      <td>0.954085</td>\n",
       "      <td>SARCASM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                             Tweets  \\\n",
       "0  twitter_1  @USER @USER @USER My 3 year old , that just fi...   \n",
       "1  twitter_2  @USER @USER How many verifiable lies has he to...   \n",
       "2  twitter_3  @USER @USER @USER Maybe Docs just a scrub of a...   \n",
       "3  twitter_4  @USER @USER is just a cover up for the real ha...   \n",
       "4  twitter_5  @USER @USER @USER The irony being that he even...   \n",
       "\n",
       "                                             cTweets   Predict       PLabel  \n",
       "0  year old finish read nietzsch ask ayo papa peo...  0.542652      SARCASM  \n",
       "1  mani verifi lie told document truth teller sur...  0.936665      SARCASM  \n",
       "2  mayb doc scrub coach mean get hammer gold stan...  0.776727      SARCASM  \n",
       "3  cover real hate insid left nutshel url hate pl...  0.297881  NOT_SARCASM  \n",
       "4  ironi even ask quit articul consid comment fin...  0.954085      SARCASM  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twittertestdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "twittertestdata.to_csv('answer_blstm.txt', columns = [\"ID\" , \"PLabel\"] , header = False , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
